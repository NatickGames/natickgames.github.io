# May 2024 Update
<img src="https://raw.githubusercontent.com/NatickGames/natickgames.github.io/main/assets/05-24-Update/AutomatedTestsBanner.png" alt="Testing with Robots">

Hey internet people! 

May has been a month focused on tech for development, specifically around automated testing. Valantis is a big game, and as a solo developer, there‚Äôs only so much time I can afford to spend checking and rechecking bugs that pop up during development. I know as I get closer to putting the game in players‚Äô hands, I‚Äôm going to need to find ways to be more confident in changes and improvements made to the game with less manual testing time. At my day job, I‚Äôm a test automation engineer, so it felt like it was long overdue for me to leverage automated testing in my game development. This update is going to be a more technical one, detailing how I set up automated tests in a way that will make future development easier.

In order to get testing off the ground, I had to make some changes to the underlying game systems to ensure I could consistently reproduce the same results from one test run to another. First, I needed to make sure that the game was deterministic, and second, I needed a way to replay or automate player input. After we look at these two changes to the game, I‚Äôll show an example of a test I have in the project now, and how this test framework makes development easier.

Buckle up, since this one is more technical and I‚Äôm walking through some code sections, it‚Äôs a long one. I promise to add pictures along the way üòõ

## Randomly the Same Every Time

<img src="https://raw.githubusercontent.com/NatickGames/natickgames.github.io/main/assets/05-24-Update/ConsistentRandomness.jpeg" alt="Consistent Randomness">

The first task I had to complete to support testing was to set up all the random calls in the game to be consistent if you give the same starting ‚Äúseed‚Äù for the number generator. This is really useful for testing, or for times when you want to be able to replicate the same experience across multiple game instances. Games like Minecraft and Valheim utilize this to allow you to share worlds, and Valantis already uses seeded randomness to generate the same map for each player in a session without having to send any more data across the network other than the map seed. 

Getting this set up would have mostly been as simple as allowing an option to set a seed for the game, except that our network code calls for random numbers a different number of times between the host player and the client players, and has to keep random numbers in sync for all players when it comes to map generation. 

(Note: This is a lot easier for me to do because this is a turn based game that doesn‚Äôt use physics. If you have to worry about whether your physics system is deterministic, or are tracking a bunch of object positions saved with floating point numbers, it‚Äôs going to be a bit more involved.)

So the solution was to create 3 random number generators. One, called the ServerRandom, handles any random calls only made on the server, which includes most random calls related to gameplay or character AI. 

Then there‚Äôs a ClientRandom, which we don‚Äôt worry about keeping in sync for each player. This is for VFX and non-gameplay related calls. A side effect of this is that environment props might be different colors for each player, and VFX might look a little different, but as long as the gameplay doesn‚Äôt incentivize you to communicate by saying ‚ÄúHe‚Äôs over there, by the red flower‚Äù players won‚Äôt notice, and it allows us to massively simplify the state we‚Äôre tracking over the network.  

The final generator is the MapRandom, which is synced between all players, host or clients, and handles map generation and any game logic that has to be run on all machines. 

With this set up, I went through the game code and moved every random call over to one of these three generators, one for server only, one for client only, and one for synced calls. I then created a single ‚Äúgame seed‚Äù that would generate the seeds for the three generators and could be easily set in code or in the editor.

With that done, I ran the game a few times with the same seed, and‚Ä¶ 

It wasn‚Äôt consistent.

<img src="https://raw.githubusercontent.com/NatickGames/natickgames.github.io/main/assets/05-24-Update/NotTheSameGame.png" alt="Two games that are probably not the same.">
<i>Two games that are probably not the same.</i>

After some investigation, it turned out I was running some C# code that wasn‚Äôt deterministic itself. Specifically, there were some places where I was iterating through HashSets and Dictionaries, which aren‚Äôt guaranteed to have any sort of consistent order. With some adjustments, I fixed those issues and now, with the same seed and making the same choices as a player, we get the same exact game. 

But that‚Äôs the catch, we need the same choices made by the player in the same order if we want to replay the same game, and for testing, we need a way to fake player input without mouse clicks, keystrokes, etc. So next we need to automate the player.

## Automating the Player

<img src="https://raw.githubusercontent.com/NatickGames/natickgames.github.io/main/assets/05-24-Update/NoHands.png" alt="Look ma, ho hands">

The goal here is to be able to play back a sequence of player actions the same way in a different game session. If we do this with the same game seed, we‚Äôll end up with the same results. There‚Äôs a couple different ways we could do this. Some approaches will just keep track of the actual inputs: key presses, mouse clicks and positioning, and replay that back. This can work, but it can be pretty brittle. If you‚Äôve ever written automated UI tests this way, you‚Äôll know the pain of all your tests breaking because someone moved a button a couple pixels over on the screen and now you‚Äôre clicking the wrong thing in your replays. This can be a valid option, specifically if you don‚Äôt have access to the code your testing, or you‚Äôre trying to test screen layout (like verifying that buttons are in the right places when a UI on a screen with different aspect ratios), but for most use cases, it just introduces a bunch of maintenance headaches while not actually adding much value. 

The alternative, and the route I took for Valantis, is to capture and replay commands. I won‚Äôt go too much into the specifics of how this part was done, but you can look at [this article](https://giannisakritidis.com/blog/Input-Replay-System/) that I referenced while building my solution if you want to learn more. The basic idea though is that rather than capturing the ‚ÄòE‚Äô key being pressed to toggle the inventory window; when the ‚ÄòE‚Äô key is pressed in game, it triggers a ‚ÄúToggleInventoryCommand‚Äù which can be saved at the end of a list of commands and played back later with the same logic. This means in a replay you exercise all the same code you do during live play, except for your actual input code. This removes the flakiness of your inputs but still allows you to test the games‚Äô logic for player actions. It‚Äôs also useful if you support multiple control schemes, like keyboard vs gamepad, as your tests don‚Äôt care what input device you‚Äôre using.

```csharp
public class EndTurnCommand : IPlayerCommand
{
    private readonly TurnManager _turnManager;
    private TurnObject _turnObject;
    
    // RECORDING - Creating this Command in-game to record it.
    public EndTurnCommand(TurnManager turnManager, TurnObject turnObject)
    {
        _turnManager = turnManager;
        _turnObject = turnObject;
    }
    
    // REPLAY - Creating this Command from saved data
    public EndTurnCommand(TurnManager turnManager, Dictionary<string, object> data)
    {
        _turnManager = turnManager;
        
        // Deserialize Saved Data to Find the Turn Object
        if (data.TryGetValue("Name", out var nameValue))
            _turnObject = _turnManager.GetTurnObject(nameValue.ToString());
        else
	        Debug.LogError("Tried to load EndTurnCommand with invalid TurnObject"); 
    }

		// Code that runs when the command is called
    public void Execute()
    {
        _turnManager.RequestTurnEnd(_turnObject, true);
    }

		// Save any required data for replay
    public Dictionary<string, object> Serialize() => new Dictionary<string, object>
    {
        {"Name", _turnObject.Name}
    };
 }
```

Here‚Äôs a (simplified a bit) example of the command to end the player‚Äôs turn. When you‚Äôre playing the game normally, you pass the TurnManager and the Player‚Äôs TurnObject and then execute the end turn request. On a replay, the command is loaded with the TurnManager and the required data to find the Player‚Äôs TurnObject in the new game session. When the command comes up in the queue, we have all the information we need to request the turn end as normal.

So I went through the game and inserted a command between each place where the player provides input and creates some sort of action. There were a couple places where the command still had to do things based on mouse position on screen, so if those things change in the future, I‚Äôll have to migrate my tests over to something better, but for the most part, the commands are based on gameplay information that isn‚Äôt dependent on screen or input schemes, and importantly, are able to be saved to disk and loaded back up at a later time. Each command saves with it some data that can be used to find the information you need to run the command when it‚Äôs replayed, assuming the game state is the same as when it was recorded, which because of our other work, it should be.

With these commands set up, you can now record a game, save the seed and player commands, and then load that information into the next game session and watch a replay of the same game you played before. This is incredibly useful! In theory, if you could set up the game to playback everything incredibly quickly, you could use this as a way to do a mid game quicksave that doesn‚Äôt require saving any state except the player commands, or you could use this for in-game replays like you‚Äôd find in something like Overwatch. What I‚Äôm concerned with using it for, however is a couple different methods of testing. 

## The Benefits for Testing

The first benefit of this system for testing is just a way to speed up bug fixing. Here‚Äôs an example scenario: you have a bug that only appears when 2 enemies of specific factions are on the same tile and you use an ability on that tile. How I would have had to troubleshoot this previously, is I‚Äôd need to find a map where this can happen through just playing and trying to get into that situation, verify that I can reproduce the issue, and try to fix it. Then I‚Äôd have to repeat this every time I wanted to try out a fix. Even with the same map seed, I couldn‚Äôt guarantee the enemies would do the same thing, or at least in order to make it more likely, I‚Äôd need to remember the exact sequence of actions I took to reproduce it each time and hope I got lucky. This is incredibly frustrating and time consuming. 

Now, with the deterministic randomness and player command playback, I can load a map once and reproduce while recording my inputs. Once I‚Äôve verified the bug, I can save the seed and command history, and replay this exact game any time I need to, without having to play it myself or remember anything. As long as the bug fix doesn‚Äôt change the number of random calls made up to that point, the replay will continue to reproduce the bug for me every time. When I make a fix, I can run the automated replay and see if it fixed it. Rinse and repeat, but now it‚Äôs quicker and there‚Äôs less to remember or do. Even better, if I was able to reproduce the bug on a minimal test map, I already have an automated regression test essentially written, I just need to write the part of the test that verifies things are the way I expect them to be. It‚Äôs better to do a test on a minimal map if possible, because that means there‚Äôs less things that will change the map seed in the future, like new rooms or zones being added to the game. 

Since that‚Äôs the case, what I really get the most value out of for testing are automated tests that just rely on the exact subset of behavior I‚Äôm testing. Let‚Äôs finish by looking at my test suite, and seeing the anatomy of one of these integration tests.

## An Example Test

I‚Äôm using [Unity‚Äôs Playmode Tests](https://docs.unity3d.com/Packages/com.unity.test-framework@1.1/manual/edit-mode-vs-play-mode-tests.html#play-mode-tests) for these integration tests. Playmode tests allow you to test GameObjects and code that uses Scenes or other aspects of the Unity API, which allows for integration testing the gameplay of the game. There‚Äôs some details in setting them up, but at it‚Äôs most basic, our tests will all be in methods that look like this:

```csharp
[UnityTest]
public IEnumerator ThisIsATest()
{
    //Test Code
}
```

Your tests have to have the UnityTest attribute so the NUnit test framework knows how to find them, and need to return an IEnumerator, which lets your test run as a coroutine so you can have it play out over multiple frames.

To start, I have some test setup that initializes the game, and a teardown that cleans up the game‚Äôs multiplayer session and anything left over that needs be reset for future tests, to make sure we don‚Äôt pollute later tests with information left over from previous tests.

I‚Äôll show how writing a test works by walking through a test I have for one of the character abilities in the game: ‚ÄúHealing Ward‚Äù. This test verifies that when you cast Healing Ward on an area, it heals allies at the end of your turn as expected.

The first line of every test takes in a path to a TestParameters object I have in my project, and uses those settings to spawn a test scene with a map, player character, and whatever else the parameters ask for.

```csharp
yield return LoadGameplayTestScene(path: "WardenTestParameters");
```

Here I‚Äôm passing a WardenTestParameters object that provides the map seed, a Warden class player character to use, and how to handle spawning scenes and NPCs. In this case, and for most tests, I want a small, single room map that won‚Äôt be affected by future changes to map generation, and I want to only spawn a single ‚ÄúTarget Dummy‚Äù NPC. An NPC with no AI that I can edit as I need to in the test code and use for target practice. The parameters object looks like this in the editor:

<img src="https://raw.githubusercontent.com/NatickGames/natickgames.github.io/main/assets/05-24-Update/WardenTestParameters.png" alt="Unity Editor view of warden test parameters">

Now that I‚Äôve got the scene set up for the test, I need to make sure the player and the target dummy are both ready to be healed at the end of the turn. I‚Äôm healing both the player and a target dummy so I can verify a few things with this test: 

1. You are considered an Ally and can be healed by your own ward
2. You can heal Allies other than yourself.
3. The healing ward heals characters on multiple tiles within it, and not just on the tile it was cast on (It‚Äôs supposed to be an AoE)

The code to do this looks like this:

```csharp
// ARRANGE
var player = Test.GetPlayer();
var target = Test.GetTargetDummy();

//Set Player and Target Health to less than 100%
player.ModifyHealth(-50);
target.ModifyHealth(-50);

var preHealPlayerHealth = player.CurrentHealth;
var preHealTargetHealth = target.CurrentHealth;

//Set Target as Ally
RelationshipService.ModifyAttitude(target.RelationshipEntity, player.RelationshipEntity, 200);
```

I have a test helper to get the player and the target dummy, and I set both of their health values below their maximum. I‚Äôm then caching that value so I can verify it‚Äôs increased once the heal happens. Then I have one more line where I improve the relationship between the dummy and the player so they‚Äôre considered Allies.

Now that we‚Äôve set up the test, it‚Äôs time to cast the ability. This is where our new PlayerCommands system really shines. Since all I need to do is provide some basic information about the ability cast to run the command, I can actually create a simple way to generate some commands in code for the test. I could also pass a player replay file into the test parameters, but I‚Äôm finding for a lot of simple tests, this is actually just easier, and lets you see the whole flow within the test code.

```csharp
//ACT - Cast Healing Ward Between Player and Target
var healingWard = Test.GetAbility("Healing Ward");
var targetTile = player.Tile.GetAdjacentTile(Direction.Left).Value;
yield return PlayerCommands.PlaybackCommands(
    Test.Command()
        .AddCastAbility(healingWard, targetTile)
        .AddEndTurn()
        .BuildCommands())
    .ToCoroutine();
```

So in this code, I get the Ability I want to cast, and the location I want to cast it in, which is a tile between the player and the target dummy that will allow the healing ward to overlap both of them. Then once that‚Äôs set, I play back an ability cast and an end turn. I‚Äôll walk through that code next.

I could break that out to be a bit easier to read like this:

```csharp
var commands = Test.Command()
        .AddCastAbility(healingWard, targetTile)
        .AddEndTurn()
        .BuildCommands();

yield return PlayerCommands.PlaybackCommands(commands).ToCoroutine();
```

The first bit uses a CommandBuilder helper in the test framework code that allows me to chain together commands and then create a replay out of them. Here I add an AbilityCast, giving it the ability I want to cast and the location I want to target, and then I add an end turn command and build the sequence.

The second statement then plays the commands back and executes them as a coroutine, so the test can wait until the commands are completed before moving to the next line. When this runs, we‚Äôll see the player cast a healing ward at the tile between the characters, wait until the ward is created, and then end their turn, triggering the ward‚Äôs end of turn heal.

Finally, we just need to check that the player and the target dummy were both healed. 

```csharp
//ASSERT - Verify Player and Target are Healed 
yield return null;

Assert.Greater(player.CurrentHealth, preHealPlayerHealth);
Assert.Greater(target.CurrentHealth, preHealTargetHealth);
```

The first line is just the way you tell a Unity Coroutine to wait for a frame before continuing. We want a frame to pass after the end turn command so that the ward heal gets a chance to happen.

Then we use asserts to make the test fail if the current health of either character is not greater than their pre-heal health.

When you put all that together, the code looks like this:

```csharp
// ARRANGE
var player = Test.GetPlayer();
var target = Test.GetTargetDummy();

//Set Player and Target Health to less than 100%
player.ModifyHealth(-50);
target.ModifyHealth(-50);

var preHealPlayerHealth = player.CurrentHealth;
var preHealTargetHealth = target.CurrentHealth;

//Set Target as Ally
RelationshipService.ModifyAttitude(target.RelationshipEntity, player.RelationshipEntity, 200);

//ACT - Cast Healing Ward Between Player and Target
var healingWard = Test.GetAbility("Healing Ward");
var targetTile = player.Tile.GetAdjacentTile(Direction.Left).Value;
var commands = Test.Command()
        .AddCastAbility(healingWard, targetTile)
        .AddEndTurn()
        .BuildCommands();

yield return PlayerCommands.PlaybackCommands(commands).ToCoroutine();
    
//ASSERT - Verify Player and Target are Healed 
yield return null;

Assert.Greater(player.CurrentHealth, preHealPlayerHealth);
Assert.Greater(target.CurrentHealth, preHealTargetHealth);
```

The test looks like this:

<video src="https://github.com/NatickGames/natickgames.github.io/assets/59749523/c5efc1a5-9112-41e1-9309-e667c5c48a15" controls="controls" style="max-width: 730px;">
</video>

And our test passes üôÇ
<img src="https://raw.githubusercontent.com/NatickGames/natickgames.github.io/main/assets/05-24-Update/PassingHealingWardTest.png" alt="Green tests are the best tests">

As I was building the Warden class this last week I created tests for each of their abilities, to make sure that future changes to the ability system when new classes are added don‚Äôt break the Warden. I‚Äôve also been able to create some tests to reproduce bugs in the game and validate their fixes.

## Wrap Up

Overall I‚Äôm really happy with this test framework, though there‚Äôs definitely some improvements I‚Äôd like to make in the future. For one, anything I can do in the game code to create simpler APIs for casting abilities, moving characters, creating effects, etc. goes a long way in making tests easier to write and easier to read. I‚Äôd also like to shore up those couple commands that are still using screen positions or mouse positions so the tests can be more resilient to UI changes. But really the biggest thing I want is just more test coverage for major features, which I‚Äôm now in a position to slowly improve on. What this test framework can‚Äôt handle at the moment is multiplayer testing, which is a bummer because a lot of the bugs that take investigation time during development are issues where something isn‚Äôt synced correctly between host and clients. I may try to do this in the future, but it would be a lot more involved and take a lot of time to develop correctly, so at the moment I‚Äôm not sure if the benefit is worth it.

I teased in there that I made a new Warden class last week. Since this update was pretty technical, I‚Äôm thinking next month I might flip to the other side of things and talk gameplay, and specifically about the Callings (or classes) in the game. That will be more of a design/gameplay focused update, which should be fun üôÇ

Until then, if you want to talk about this testing work or anything else Valantis, hop into the Valantis channels on the [Tarodev](https://discord.gg/tarodev) and [FishNetworking](https://discord.gg/firstgeargames-fish-networking-424284635074134018) discords. 

\- Dekori